version: '3.8'

services:
  dots-ocr-server:
    image: dots-ocr:latest
    container_name: dots-ocr-container
    ports:
      - "8000:8000"
    volumes:
      - ./model/dots.ocr:/workspace/weights/DotsOCR
    environment:
      - PYTHONPATH=/workspace/weights:$PYTHONPATH
      - NVIDIA_VISIBLE_DEVICES=0
    runtime: nvidia
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -ex;
        sed -i '/^from vllm\.entrypoints\.cli\.main import main/a from DotsOCR import modeling_dots_ocr_vllm' $(which vllm);
        exec vllm serve /workspace/weights/DotsOCR \
            --tensor-parallel-size 1 \
            --gpu-memory-utilization 0.8 \
            --chat-template-content-format string \
            --served-model-name dotsocr-model \
            --trust-remote-code
